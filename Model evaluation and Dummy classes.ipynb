{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice from this link: https://github.com/lytemar/Applied-Machine-Learning-in-Python--University-of-Michigan---Coursera/blob/master/Module%203.ipynb\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 178\n",
      "1 182\n",
      "2 177\n",
      "3 183\n",
      "4 181\n",
      "5 182\n",
      "6 181\n",
      "7 179\n",
      "8 174\n",
      "9 180\n"
     ]
    }
   ],
   "source": [
    "for class_name, class_count in zip(dataset.target_names, np.bincount(dataset.target)):\n",
    "    print(class_name, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No lets create an imbalance binary class.\n",
    "# We define digit 1 as positive class and other digits as negative class\n",
    "y1 = y.copy()\n",
    "y1[y1 != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1615\n",
      "1 182\n"
     ]
    }
   ],
   "source": [
    "for class_name, class_count in zip(dataset.target_names, np.bincount(y1)):\n",
    "    print(class_name, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9] \n",
      " [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y[0:20] ,'\\n',  y1[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score on train data of an imbalanced binary class 1.000\n",
      "SVC score on test data of an imbalanced binary class 0.909\n"
     ]
    }
   ],
   "source": [
    "# For this imbalance binary class we want to see how good is the SVC model.\n",
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, random_state = 0)\n",
    "clf = SVC(kernel='rbf', C = 1, gamma='auto').fit(X_train, y_train)\n",
    "print('SVC score on train data of an imbalanced binary class {:.3f}'.format(clf.score(X_train, y_train)))\n",
    "print('SVC score on test data of an imbalanced binary class {:.3f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy score on train data of an imbalanced binary class 0.90\n",
      "Dummy score on test data of an imbalanced binary class 0.90\n"
     ]
    }
   ],
   "source": [
    "# Lets compare with the results of a Dummy classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "print('Dummy score on train data of an imbalanced binary class {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Dummy score on test data of an imbalanced binary class {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How the prediction of the Dummy classifier looks like?\n",
    "Dummy_prediction = clf.predict(X_test)\n",
    "Dummy_prediction\n",
    "# You see it only has 0! Not very suprised by score of dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel score on an imbalanced binary class 0.98\n"
     ]
    }
   ],
   "source": [
    "# SVC with kernel = linear\n",
    "clf = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print('SVC with linear kernel score on an imbalanced binary class {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[407,   0],\n",
       "       [ 43,   0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "dummy_most_frequenct = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "y_predicted = dummy_most_frequenct.predict(X_test)\n",
    "confusion_matrix(y_test, y_predicted)\n",
    "# Look dummyclassifier predicts 407 negative class correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random class-proportional prediction (dummy classifier): \n",
      " [[368  39]\n",
      " [ 38   5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "clf = DummyClassifier(strategy='stratified').fit(X_train, y_train)\n",
    "y_predicted_stra_strati = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_predicted_stra_strati)\n",
    "print('Random class-proportional prediction (dummy classifier): \\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with linear kernel prediction: \n",
      " [[402   5]\n",
      " [  5  38]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_SVC = SVC(kernel='linear', C =1).fit(X_train, y_train)\n",
    "y_SVC_prediction = clf_SVC.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_SVC_prediction)\n",
    "print('SVC with linear kernel prediction: \\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression confusion matric: \n",
      " [[401   6]\n",
      " [  8  35]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0125384\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "y_logreg_prediction = logreg.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_logreg_prediction)\n",
    "print('LogisticRegression confusion matric: \\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier confusion matric: \n",
      " [[405   2]\n",
      " [  9  34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_tree = DecisionTreeClassifier(max_depth=4).fit(X_train, y_train)\n",
    "y_tree_prediction = clf_tree.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_tree_prediction)\n",
    "print('Decision tree classifier confusion matric: \\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with rbf kernel classifier confusion matric: \n",
      " [[407   0]\n",
      " [ 41   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_SVC_rbf = SVC(kernel='rbf', gamma='auto').fit(X_train, y_train)\n",
    "y_SVC_rbf_prediction = clf_SVC_rbf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_SVC_rbf_prediction)\n",
    "print('SVC with rbf kernel classifier confusion matric: \\n', confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy, Precision, Recall and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Precision: 0.89\n",
      "Recall: 0.79\n",
      "F1 score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf_tree = DecisionTreeClassifier(max_depth=4).fit(X_train ,y_train)\n",
    "y_predicted_clf_tree = clf_tree.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_predicted_clf_tree)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_predicted_clf_tree)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_predicted_clf_tree)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, y_predicted_clf_tree)))\n",
    "print('F1 score: {:.2f}'.format(f1_score(y_test, y_predicted_clf_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Accuracy: 0.90\n",
      "Dummy Precision: 0.00\n",
      "Dummy Recall: 0.00\n",
      "Dummy F1 score: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0125384\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf_dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "y_predicted_clf_dummy = clf_dummy.predict(X_test)\n",
    "print('Dummy Accuracy: {:.2f}'.format(accuracy_score(y_test, y_predicted_clf_dummy)))\n",
    "print('Dummy Precision: {:.2f}'.format(precision_score(y_test, y_predicted_clf_dummy)))\n",
    "print('Dummy Recall: {:.2f}'.format(recall_score(y_test, y_predicted_clf_dummy)))\n",
    "print('Dummy F1 score: {:.2f}'.format(f1_score(y_test, y_predicted_clf_dummy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "other numbers       0.98      0.99      0.98       407\n",
      "            1       0.89      0.79      0.84        43\n",
      "\n",
      "     accuracy                           0.97       450\n",
      "    macro avg       0.94      0.89      0.91       450\n",
      " weighted avg       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predicted_clf_tree, target_names=['other numbers', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
